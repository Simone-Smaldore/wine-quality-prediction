{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo progetto andrò ad utilizzare alcune librerie di python (numpy e pandas per la gestione dei dati , pyplot e seaborn per disegnare i grafici e scikit-learn per gli algoritmi di learning) per risolvere due tasks:\n",
    "- Partendo in maniera arbitraria da uno dei due dataset, andrò a calcolare la qualità di un vino in base alle sue caratteristiche chimiche.\n",
    "- Prendendo in considerazione entrambi i dataset andrò a verificare se un vino è bianco o rosso sempre in base alle stesse caratteristiche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primo problema Classificazione dei vini in base alla qualità "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import e caricamento dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho caricato il dataset winequality-red.csv\n"
     ]
    }
   ],
   "source": [
    "# CARICAMENTO DEI DATI\n",
    "\n",
    "# SCELTA DEL DATASET\n",
    "#nome_dataset = \"winequality-white.csv\";\n",
    "nome_dataset = \"winequality-red.csv\";\n",
    "\n",
    "dataset = pd.read_csv(nome_dataset, sep=\";\")\n",
    "colonne = dataset.columns.tolist()\n",
    "X = dataset[colonne[:-1]] \n",
    "y = dataset[colonne[-1]] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# PER QUESTA LIBRERIA NON GENERO IL CROSS-VALIDATION VISTO CHE AUTOMATIZZA IL TUTTO\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "print(\"Ho caricato il dataset\", nome_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descrizione e stampa dei dati "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DESCRIZIONE DEI DATI \n",
    "\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAMPA DISTRIBUZIONE DELLE LABEL\n",
    "\n",
    "plt.bar(dataset[colonne[-1]].value_counts().sort_index().index, dataset[colonne[-1]].value_counts().sort_index().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIMA STAMPA DEI DATI POSSO VEDERE LA DISTRIBUZIONE DI DUE VARIABILI RISPETTO AD OGNI QUALITA\n",
    "\n",
    "feature_1 = 6\n",
    "feature_2 = 5\n",
    "sns.relplot(\n",
    "    data=dataset, x=colonne[feature_1], y=colonne[feature_2], col=colonne[-1], height=4, aspect=.7, col_wrap=4\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECONDA STAMPA IN QUESTO CASO VADO A VEDERE PER UNA FEATURE SCELTA TRAMITE UNA VARIABILE COLONNA_PLOT LA DISTIBUZIONE IN \n",
    "# PERCENTUALE DEI NUM_INTERVALLI INTERVALLI UTILIZZATI PER OGNI QUANTITA\n",
    "\n",
    "# DISCRETIZZO TUTTE LE FEATURES IN MODO DA POTER STAMPARE SEMPLICEMENTE UN STIMA DI COME VA OGNI COLONNA\n",
    "\n",
    "num_intervalli = 8\n",
    "colonna_plot = 9\n",
    "\n",
    "\n",
    "dataplot = dataset.copy()\n",
    "for colonna in range(len(colonne) - 1):\n",
    "    minimo = dataset[colonne[colonna]].min()\n",
    "    massimo = dataset[colonne[colonna]].max()\n",
    "    passo = (massimo-minimo)/(num_intervalli - 1)\n",
    "    bins = np.arange(minimo, massimo, passo)\n",
    "    if(len(bins) == num_intervalli - 1):\n",
    "        bins = np.append(np.arange(minimo, massimo, passo), massimo)\n",
    "    nuova_colonna = np.digitize(dataset[colonne[colonna]],bins,right=True) \n",
    "    dataplot[colonne[colonna]] = nuova_colonna + 1\n",
    "    \n",
    "# GENERO LA MATRICE MAT CONTANDO LE OCCORRENZE DI OGNI VALORE DISCRETO PER OGNI QUANTITÀ POSSIBILE IN USCITA\n",
    "\n",
    "mat = np.zeros((num_intervalli,10)) \n",
    "for j in range(len(dataplot)):\n",
    "    mat[dataplot[colonne[colonna_plot]][j] -1 , dataplot[colonne[-1]][j] - 1]+=1\n",
    "    \n",
    "    \n",
    "# GENERO LA MATRICE MAT_PERCENTUALI ANDANDO A CALCOLARE UNA STATISTICA SU QUANTO É PRESENTE OGNI VALORE DISCRETO\n",
    "\n",
    "somma_colonne=sum(mat)\n",
    "mat_percentuali = mat.copy()\n",
    "num_righe, num_colonne = mat.shape\n",
    "for i in range(num_righe):\n",
    "    for j in range(num_colonne):\n",
    "        if(somma_colonne[j] == 0):\n",
    "            mat_percentuali[i, j] = 0\n",
    "        else:\n",
    "            mat_percentuali[i, j] = mat[i, j] / somma_colonne[j]\n",
    "\n",
    "# STAMPA DEI GRAFICI LE QUALITA SONO SOLO DA 1 A 9 VISTO CHE IN QUESTI DATASET AL MASSIMO ABBIAMO QUALITA TRA 3 E 9\n",
    "\n",
    "names= list(range(1,num_intervalli + 1))\n",
    "fig, axs = plt.subplots(3, 3)\n",
    "zoom = 3\n",
    "w, h = fig.get_size_inches()\n",
    "fig.set_size_inches(w * zoom, h * zoom)\n",
    "axs[0, 0].bar(names, mat_percentuali[:, 0])\n",
    "axs[0, 0].set_title('qualità 1')\n",
    "axs[0, 1].bar(names, mat_percentuali[:, 1])\n",
    "axs[0, 1].set_title('qualità 2')\n",
    "axs[0, 2].bar(names, mat_percentuali[:, 2])\n",
    "axs[0, 2].set_title('qualità 3')\n",
    "axs[1, 0].bar(names, mat_percentuali[:, 3])\n",
    "axs[1, 0].set_title('qualità 4')\n",
    "axs[1, 1].bar(names, mat_percentuali[:, 4])\n",
    "axs[1, 1].set_title('qualità 5')\n",
    "axs[1, 2].bar(names, mat_percentuali[:, 5])\n",
    "axs[1, 2].set_title('qualità 6')\n",
    "axs[2, 0].bar(names, mat_percentuali[:, 6])\n",
    "axs[2, 0].set_title('qualità 7')\n",
    "axs[2, 1].bar(names, mat_percentuali[:, 7])\n",
    "axs[2, 1].set_title('qualità 8')\n",
    "axs[2, 2].bar(names, mat_percentuali[:, 8])\n",
    "axs[2, 2].set_title('qualità 9')\n",
    "fig.suptitle('Statistiche per la colonna ' + colonne[colonna_plot], fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TERZA STAMPA MATRICE DI CORRELAZIONE\n",
    "\n",
    "corr = dataset.corr()\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "fig.suptitle('Matrice di correlazione', fontsize=16)\n",
    "sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling delle features effettuato\n"
     ]
    }
   ],
   "source": [
    "X_train_scal = X_train.copy()\n",
    "X_test_scal = X_test.copy()\n",
    "scale = StandardScaler().fit(X_train_scal)\n",
    "X_train_scal = scale.transform(X_train_scal)\n",
    "X_test_scal = scale.transform(X_test_scal)\n",
    "\n",
    "#PER RITRASFORMARLI IN DATAFRAME\n",
    "\n",
    "X_train_scal = pd.DataFrame(data=X_train_scal, index=X_train.index, columns=[colonne[:-1]])\n",
    "X_test_scal = pd.DataFrame(data=X_test_scal, index=X_test.index, columns=[colonne[:-1]])\n",
    "\n",
    "# PER QUESTA LIBRERIA NON GENERO IL CROSS-VALIDATION VISTO CHE AUTOMATIZZA IL TUTTO\n",
    "#X_val_scal = X_val.copy()\n",
    "#X_val_scal = scale.transform(X_val_scal)\n",
    "#X_val_scal = pd.DataFrame(data=X_val_scal, index=X_val.index, columns=[colonne[:-1]])\n",
    "\n",
    "print(\"Scaling delle features effettuato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training e calcolo dell'accuratezza dei diversi algoritmi settati a 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effettuo il training per 6 diversi algoritmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza di Random Forest = 0.825\n"
     ]
    }
   ],
   "source": [
    "esegui_DT = 0   # DECISION TREE\n",
    "esegui_SVM = 0  # SVM\n",
    "esegui_RL = 0   # REGRESSIONE LOGISTICA\n",
    "esegui_NB = 0   # NAIVE BAYES\n",
    "esegui_RF = 1   # RANDOM FOREST\n",
    "esegui_NN = 0   # RETE NEURALE\n",
    "\n",
    "def scegli_modello(parametri, algoritmo, X, y):\n",
    "    modello = GridSearchCV(algoritmo, parametri)\n",
    "    modello.fit(X, y)\n",
    "    return modello\n",
    "  \n",
    "def calcola_accuratezza_modello(modello, X_test, y_test, nome_algoritmo):\n",
    "    predizione= modello.predict(X_test)\n",
    "    print(\"Accuratezza di \" + nome_algoritmo + \" = \" + str(accuracy_score(y_test, predizione)))\n",
    "    return predizione\n",
    "\n",
    "if(esegui_DT == 1):\n",
    "    parametri_DT = {'criterion':('gini', 'entropy')}\n",
    "    modello_DT = scegli_modello(parametri_DT, DecisionTreeClassifier(), X_train_scal, y_train)\n",
    "    best_params_DT = modello_DT.best_params_\n",
    "    pred_DT = calcola_accuratezza_modello(modello_DT, X_test_scal, y_test, \"Decision Tree\")\n",
    "    \n",
    "if(esegui_SVM == 1):\n",
    "    parametri_SVM = {'C':np.logspace(-1, 5, 4)}\n",
    "    modello_SVM = scegli_modello(parametri_SVM, SVC(), X_train_scal, y_train)\n",
    "    best_params_SVM = modello_SVM.best_params_\n",
    "    pred_SVM = calcola_accuratezza_modello(modello_SVM, X_test_scal, y_test, \"SVM\")\n",
    "    \n",
    "if(esegui_RL == 1):\n",
    "    parametri_RL = {'C':np.logspace(9, 10, 3)}\n",
    "    modello_RL = scegli_modello(parametri_RL, LogisticRegression(max_iter=400), X_train_scal, y_train)\n",
    "    best_params_RL = modello_RL.best_params_\n",
    "    pred_RL = calcola_accuratezza_modello(modello_RL, X_test_scal, y_test, \"Regressione Logistica\")\n",
    "\n",
    "if(esegui_NB == 1):\n",
    "    parametri_NB = {'var_smoothing': np.logspace(0,-9, num=300)}\n",
    "    modello_NB = scegli_modello(parametri_NB, GaussianNB(), X_train_scal, y_train)\n",
    "    best_params_NB = modello_NB.best_params_\n",
    "    pred_NB = calcola_accuratezza_modello(modello_NB, X_test_scal, y_test, \"Naive Bayes\")\n",
    "\n",
    "if(esegui_RF == 1):\n",
    "    parametri_RF = {'max_depth': [10, 20, 30], 'min_samples_leaf':[3 ,10, 30, 100]}\n",
    "    modello_RF = scegli_modello(parametri_RF, RandomForestClassifier(n_estimators=1000), X_train_scal, y_train)\n",
    "    best_params_RF = modello_RF.best_params_\n",
    "    pred_RF = calcola_accuratezza_modello(modello_RF, X_test_scal, y_test, \"Random Forest\")\n",
    "    \n",
    "if(esegui_NN == 1):\n",
    "    parametri_NN = {'alpha':np.logspace(-3, 1, 5)}\n",
    "    modello_NN = scegli_modello(parametri_NN, MLPClassifier(hidden_layer_sizes=(1000, 500, 300, 30, 10), max_iter=600), X_train_scal, y_train)\n",
    "    best_params_NN = modello_NN.best_params_\n",
    "    pred_NN = calcola_accuratezza_modello(modello_NN, X_test_scal, y_test, \"NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stampa delle curve di learning dei diversi algoritmi settati a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esegui_DT = 0   # DECISION TREE\n",
    "esegui_SVM = 0  # SVM\n",
    "esegui_RL = 0   # REGRESSIONE LOGISTICA\n",
    "esegui_NB = 0   # NAIVE BAYES\n",
    "esegui_RF = 1   # RANDOM FOREST\n",
    "esegui_NN = 0   # RETE NEURALE\n",
    "\n",
    "def plot_learning_curves(X, y, modello, nome_algoritmo):\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(estimator = modello, X = X, y = y)\n",
    "    validation_mean = np.mean(validation_scores, axis=1)\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    plt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training\")\n",
    "    plt.plot(train_sizes, validation_mean, color=\"#111111\", label=\"Cross-validation\")\n",
    "    plt.title(\"Curve di learning per \" + nome_algoritmo)\n",
    "    plt.xlabel(\"Dimensione Training Set\"), plt.ylabel(\"Accuratezza\"), plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "if(esegui_DT == 1 and 'modello_DT' in locals()):\n",
    "    plot_learning_curves(X_train_scal, y_train, DecisionTreeClassifier(**best_params_DT), 'Decision Tree')\n",
    "    \n",
    "if(esegui_SVM == 1 and 'modello_SVM' in locals()):\n",
    "    plot_learning_curves(X_train_scal, y_train, SVC(**best_params_SVM), 'SVM')    \n",
    "\n",
    "if(esegui_RL == 1 and 'modello_RL' in locals()):\n",
    "    plot_learning_curves(X_train_scal, y_train, LogisticRegression(**best_params_RL, max_iter=100), 'Regressione Logistica')    \n",
    "\n",
    "if(esegui_NB == 1 and 'modello_NB' in locals()):\n",
    "    plot_learning_curves(X_train_scal, y_train, GaussianNB(**best_params_NB), 'Naive Bayes')\n",
    "\n",
    "if(esegui_RF == 1 and 'modello_RF' in locals()):\n",
    "    plot_learning_curves(X_train_scal, y_train, RandomForestClassifier(**best_params_RF, n_estimators=1000), 'Random Forest')\n",
    "\n",
    "if(esegui_RF == 1 and 'modello_NN' in locals()):\n",
    "    plot_learning_curves(X_train_scal, y_train, MLPClassifier(hidden_layer_sizes=(1000, 500, 300), max_iter=600, **best_params_NN), 'Rete Neurale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo dell statistiche per i diversi algoritmi settati a 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix per il Random Forest\n",
      "\n",
      "[[986   2]\n",
      " [  5 307]]\n",
      "\n",
      "Precision e Recall per il Random Forest\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       988\n",
      "           1       0.99      0.98      0.99       312\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "esegui_DT = 1   # DECISION TREE\n",
    "esegui_SVM = 1  # SVM\n",
    "esegui_RL = 1   # REGRESSIONE LOGISTICA\n",
    "esegui_NB = 1   # NAIVE BAYES\n",
    "esegui_RF = 1   # RANDOM FOREST\n",
    "esegui_NN = 1   # RETE NEURALE\n",
    "\n",
    "if(esegui_DT == 1 and 'pred_DT' in locals()):\n",
    "    print(\"\\nConfusion Matrix per il Decision Tree\\n\")\n",
    "    print(str(confusion_matrix(y_test, pred_DT)))\n",
    "    print(\"\\nPrecision e Recall per il Decision Tree\\n\")\n",
    "    print(classification_report(y_test, pred_DT))\n",
    "    \n",
    "if(esegui_SVM == 1 and 'pred_SVM' in locals()):\n",
    "    print(\"\\nConfusion Matrix per SVM\\n\")\n",
    "    print(str(confusion_matrix(y_test, pred_SVM)))\n",
    "    print(\"\\nPrecision e Recall per SVM\\n\")\n",
    "    print(classification_report(y_test, pred_SVM))\n",
    "    \n",
    "if(esegui_RL == 1 and 'pred_RL' in locals()):\n",
    "    print(\"\\nConfusion Matrix per la Regressione Logistica\\n\")\n",
    "    print(str(confusion_matrix(y_test, pred_RL)))\n",
    "    print(\"\\nPrecision e Recall per la Regressione Logistica\\n\")\n",
    "    print(classification_report(y_test, pred_RL))\n",
    "\n",
    "if(esegui_NB == 1 and 'pred_NB' in locals()):\n",
    "    print(\"\\nConfusion Matrix per il Naive Bayes\\n\")\n",
    "    print(str(confusion_matrix(y_test, pred_NB)))\n",
    "    print(\"\\nPrecision e Recall per il Naive Bayes\\n\")\n",
    "    print(classification_report(y_test, pred_NB))\n",
    "\n",
    "if(esegui_RF == 1 and 'pred_RF' in locals()):\n",
    "    print(\"\\nConfusion Matrix per il Random Forest\\n\")\n",
    "    print(str(confusion_matrix(y_test, pred_RF)))\n",
    "    print(\"\\nPrecision e Recall per il Random Forest\\n\")\n",
    "    print(classification_report(y_test, pred_RF))\n",
    "    \n",
    "if(esegui_NN == 1 and 'pred_NN' in locals()):\n",
    "    print(\"\\nConfusion Matrix per la Rete Neurale\\n\")\n",
    "    print(str(confusion_matrix(y_test, pred_NN)))\n",
    "    print(\"\\nPrecision e Recall per la rete Neurale\\n\")\n",
    "    print(classification_report(y_test, pred_NN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primo accorpamento delle label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essendoci pochi vini alle fascie estreme rispetto ai vini di fascia media vado ad accorpare i vini di qualità 3 con i vini di qualità 4 e quelli di qualità 8 e 9 con quelli di qualità 7. Rieseguo poi il learning, il plot e calcolo le statistiche e osservo che le prestazioni migliorano di poco. Inizio però ad individuare l'algoritmo con prestazioni migliori su cui concentrarmi: Il Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.replace(3, 4)\n",
    "y_test = y_test.replace(9, 7)\n",
    "y_test = y_test.replace(8, 7)\n",
    "\n",
    "y_train = y_train.replace(3, 4)\n",
    "y_train = y_train.replace(9, 7)\n",
    "y_train = y_train.replace(8, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondo accorpamento delle label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osservo che ho bisogno di accorpare ancora per miglorare le prestazioni: Accorpo allora i vini di qualità 4 (a cui avevo aggiunto precedentemente quelli di qualità 3) con i vini di qualità 5 in modo da ottenere tre classi di vini: bassa media ed alta qualità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.replace(4, 5)\n",
    "y_test = y_test.replace(5, 0)\n",
    "y_test = y_test.replace(6, 1)\n",
    "y_test = y_test.replace(7, 2)\n",
    "\n",
    "y_train = y_train.replace(4, 5)\n",
    "y_train = y_train.replace(5, 0)\n",
    "y_train = y_train.replace(6, 1)\n",
    "y_train = y_train.replace(7, 2)\n",
    "\n",
    "# IN QUESTO MODO OTTENGO UN'ACCURATEZZA DEL 70% CON IL RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accorpando in questo modo ottengo un'accuratezza del 71% per i vini bianchi e del 74% per i vini rossi. In questo modo l'accuratezza non è molto alta ma l'f-measure delle tre diverse classi è bilanciato. Nel caso avessimo accorpato i vini di qualità 5 con quelli di qualità 6 invece che con quelli di qualità 4, avremmo ottenuto un'accuratezza abbastanza alta, ma solamente perchè la maggior parte dei vini sarebbe ricaduta nei vini di qualità media. In questo modo però, l'algoritmo sarebbe andato a prevedere solo vini di media qualità avendo per le altre due classi un f-measure basso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terzo accorpamento delle label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andando ad accorpare ulteriormente le classi unendo le classe dei vini di media qualità con quella dei vini di alta qualità, riduco il problema ad un problema di classificazione binaria. In questo modo con il random forest raggiungo un f-measure del 82%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.replace(2, 1)\n",
    "y_train = y_train.replace(2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondo problema classificazione di vini rossi e vini bianchi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caricamento dei dati e generazione del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bianchi = pd.read_csv(\"winequality-white.csv\", sep=\";\")\n",
    "rossi = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "bianchi[\"colore\"]=0;\n",
    "rossi[\"colore\"]=1; \n",
    "dataset = pd.concat([bianchi, rossi], ignore_index = True)\n",
    "colonne = dataset.columns.tolist()\n",
    "X = dataset[colonne[:-1]] \n",
    "y = dataset[colonne[-1]]  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto riscrivo solamente il codice per eseguire Il Random Forest per semplicità; In ogni caso potrei rieseguire lo stesso codice di prima anche per questo problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuratezza di Random Forest = 0.9946153846153846\n",
      "\n",
      "Confusion Matrix per il Random Forest\n",
      "\n",
      "[[986   2]\n",
      " [  5 307]]\n",
      "\n",
      "Precision e Recall per il Random Forest\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       988\n",
      "           1       0.99      0.98      0.99       312\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_scal = X_train.copy()\n",
    "X_test_scal = X_test.copy()\n",
    "scale = StandardScaler().fit(X_train_scal)\n",
    "X_train_scal = scale.transform(X_train_scal)\n",
    "X_test_scal = scale.transform(X_test_scal)\n",
    "X_train_scal = pd.DataFrame(data=X_train_scal, index=X_train.index, columns=[colonne[:-1]])\n",
    "X_test_scal = pd.DataFrame(data=X_test_scal, index=X_test.index, columns=[colonne[:-1]])\n",
    "\n",
    "parametri_RF = {'max_depth': [10, 20, 30], 'min_samples_leaf':[3 ,10, 30, 100]}\n",
    "modello_RF = scegli_modello(parametri_RF, RandomForestClassifier(n_estimators=1000), X_train_scal, y_train)\n",
    "best_params_RF = modello_RF.best_params_\n",
    "pred_RF = calcola_accuratezza_modello(modello_RF, X_test_scal, y_test, \"Random Forest\")\n",
    "\n",
    "\n",
    "print(\"\\nConfusion Matrix per il Random Forest\\n\")\n",
    "print(str(confusion_matrix(y_test, pred_RF)))\n",
    "print(\"\\nPrecision e Recall per il Random Forest\\n\")\n",
    "print(classification_report(y_test, pred_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per questo problema ho ottenuto delle prestazioni ottime in quanto con il Random Forest raggiungo un'f-measure del 99.5%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
